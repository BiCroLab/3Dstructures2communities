{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import umap\n",
    "\n",
    "import cdlib\n",
    "from cdlib import algorithms\n",
    "import networkx as nx\n",
    "from  scipy import sparse\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(XYZ):\n",
    "    adj = umap.umap_.fuzzy_simplicial_set(\n",
    "        XYZ,\n",
    "        n_neighbors=5, # this parameter has to be fine-tuned\n",
    "        random_state=np.random.RandomState(seed=42),\n",
    "        metric='l2',\n",
    "        metric_kwds={},\n",
    "        knn_indices=None,\n",
    "        knn_dists=None,\n",
    "        angular=False,\n",
    "        set_op_mix_ratio=1.0,\n",
    "        local_connectivity=2.0,\n",
    "        verbose=False\n",
    "        )\n",
    "    return adj\n",
    "\n",
    "def build_communities(adj):\n",
    "    g = nx.from_scipy_sparse_matrix(adj) # generate a graph networkx obj\n",
    "    eset = [(u, v) for (u, v, d) in g.edges(data=True)] # get list of edges from graph\n",
    "    weights = [d['weight'] for (u, v, d) in g.edges(data=True)] # get list of weights from edges\n",
    "    # find communities\n",
    "    # in this example we use the Leiden algorithm\n",
    "    leiden_coms = algorithms.leiden(g,weights=weights) # check if the algo is stochastic, in that case set rnd generator    \n",
    "    return leiden_coms.communities # a list of lists of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random 3D structures\n",
    "# 100 random (x,y,z)-tuples of 1000 bins each \n",
    "\n",
    "structures = np.random.default_rng().uniform(-100,100,(1000,3,100))\n",
    "max_numb_str = 10\n",
    "numb_str = structures.shape[2]\n",
    "numb_loci = structures.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each structure to a weighted graph\n",
    "# In this example we use UMAP\n",
    "comm = {}\n",
    "for structure in range(numb_str)[:max_numb_str]: # for each structure\n",
    "    XYZ = structures[:,:,structure] # get the x,y,z coordinates\n",
    "    adj = build_graph(XYZ) # get the graph\n",
    "    comm[structure] = build_communities(adj) # get the communities of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The matrix P is the analog of the HiC matrix:\n",
    "# P(i,j) = # times loci (i,j) occur together \n",
    "for structure in range(numb_str)[:max_numb_str]: # for each structure\n",
    "    for c in range(len(comm[structure])):        # for each community in the given structure\n",
    "        if c == 0: # for the first community define the graph G\n",
    "            G = nx.complete_graph(comm[structure][c])\n",
    "        else: # for the other communities update G\n",
    "            G.update(nx.complete_graph(comm[structure][c]))\n",
    "    if structure == 0: # for the first structure define the sparse matrix P\n",
    "        P = nx.to_scipy_sparse_matrix(G, nodelist=range(numb_loci))\n",
    "    else: # for the other structures add to P\n",
    "        P += nx.to_scipy_sparse_matrix(G, nodelist=range(numb_loci)) \n",
    "    #print(P.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use NMF to decompose the V matrix similarly to what is done in word X document decomposition \n",
    "# The matrix V is #pairs X #structures matrix:\n",
    "# V[(i,j),s] = 1 if the pair of loci (i,j) occurs in structure s\n",
    "\n",
    "for structure in range(numb_str)[:max_numb_str]: # for each structure\n",
    "    for c in range(len(comm[structure])):        # for each community in the given structure\n",
    "        if c == 0: # for the first community define the graph G\n",
    "            G = nx.complete_graph(comm[structure][c])\n",
    "        else: # for the other communities update G\n",
    "            G.update(nx.complete_graph(comm[structure][c]))\n",
    "    \n",
    "    if structure == 0: # for the first structure define the sparse matrix sparse_structure_2d\n",
    "        node_i = [e[0] for e in G.edges]\n",
    "        node_j = [e[1] for e in G.edges]\n",
    "        s = [structure for e in G.edges]\n",
    "        sparse_structure = sparse.coo_matrix((s, (node_i, node_j)), \n",
    "                                             shape=(numb_loci, numb_loci), dtype=np.int8)\n",
    "        # reshape to 1d sparse array\n",
    "        sparse_structure_1d = sparse_structure.reshape((numb_loci*numb_loci,1))\n",
    "        # build the 2d edgesXstructure sparse array:\n",
    "        rows = sparse_structure_1d.row # the occurring pairs\n",
    "        cols = [v for v in sparse_structure_1d.data] # the occurring structures\n",
    "        data = [1]*len(sparse_structure_1d.data) # 1 if loci pair is in structures\n",
    "        V = sparse.coo_matrix((data, (rows, cols)),\n",
    "                              shape=(numb_loci*numb_loci,max_numb_str),\n",
    "                              dtype=np.int8) # define the V matrix\n",
    "    else:\n",
    "        node_i = [e[0] for e in G.edges]\n",
    "        node_j = [e[1] for e in G.edges]\n",
    "        s = [structure for e in G.edges]\n",
    "        sparse_structure = sparse.coo_matrix((s, (node_i, node_j)), \n",
    "                                             shape=(numb_loci, numb_loci), dtype=np.int8)\n",
    "        # reshape to 1d sparse array\n",
    "        sparse_structure_1d = sparse_structure.reshape((numb_loci*numb_loci,1))\n",
    "        # build the new 2d edgesXstructure sparse array:\n",
    "        rows = sparse_structure_1d.row\n",
    "        cols = [v for v in sparse_structure_1d.data]\n",
    "        data = [1]*len(sparse_structure_1d.data)\n",
    "        # concatenate old and new data\n",
    "        data = np.concatenate((V.data, data))\n",
    "        rows = np.concatenate((V.row, rows))\n",
    "        cols = np.concatenate((V.col, cols))\n",
    "        V = sparse.coo_matrix((data, (rows, cols)),\n",
    "                              shape=(numb_loci*numb_loci,max_numb_str),\n",
    "                              dtype=np.int8) # update the V matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=2, init='nndsvd', random_state=0)\n",
    "W = model.fit_transform(V)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 10) (1000000, 2) (2, 10)\n"
     ]
    }
   ],
   "source": [
    "print(V.shape,W.shape,H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([19]), array([88]))"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the node_i and node_j labels from the rows of the V matrix\n",
    "row_V_matrix = 19088\n",
    "np.unravel_index([row_V_matrix],  (numb_loci,numb_loci))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
